%% The MIT License (MIT)
%%
%% Copyright (c) 2015 Daniil Belyakov
%%
%% Permission is hereby granted, free of charge, to any person obtaining a copy
%% of this software and associated documentation files (the "Software"), to deal
%% in the Software without restriction, including without limitation the rights
%% to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
%% copies of the Software, and to permit persons to whom the Software is
%% furnished to do so, subject to the following conditions:
%%
%% The above copyright notice and this permission notice shall be included in all
%% copies or substantial portions of the Software.
%%
%% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
%% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
%% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
%% AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
%% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
%% OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
%% SOFTWARE.

\documentclass[]{mcdowellcv}

% For mathematical symbols
\usepackage{amsmath}

% Set applicant's personal data for header
\name{Aldo Escobar}
\address{Moldes 1435 14E \linebreak CABA, Argentina}
\contacts{3814144677 \linebreak aoelvp94@gmail.com \linebreak 11/11/1994}

\begin{document}

% Print the header
\makeheader

% Print the content
\begin{cvsection}{EXPERIENCIA LABORAL}
	\begin{cvsubsection}{Data Mining Analyst}{dataEvo}{Agosto 2018 - Mayo 2019}
		\begin{itemize}
			\item Análisis de datos y creación de visualizaciones usando datos de Twitter para campañas políticas.
			\item Creación de dashboards usando Shiny para presentar resultados del algoritmo devoBooster (modelo propio).
			\item Desarrollo y mejora de modelos de aprendizaje no supervisado para entender y mejorar la performance de devoBooster.
		\end{itemize}
	\end{cvsubsection}
	
	\begin{cvsubsection}{Data Engineer}{Nubimetrics}{Mayo 2019 - Diciembre 2019}
		\begin{itemize}
			\item Tratado de outliers y armado de algoritmos dedetección de valores anómalos.
			\item Refactorización de la solución core de Nubimetrics migrando funciones hechas en Spark SQL a funciones nativas de Spark, implementando tests unitarios y de integración.
			\item Automatización de procesos de ETL y de reporting usando servicios de Azure.
		\end{itemize}
	\end{cvsubsection}
	
	\begin{cvsubsection}{Data Engineer}{Mutt Data}{Diciembre 2019 - Actualidad}
		\begin{itemize}
			\item Ayudar en la creación de ETLs para migraciones de datos desde Teradata hacia Athena aportando mecanismos de validación de datos.
			\item Participación como docente de un seminario de Digital House brindando seminarios sobre Apache Airflow y Apache Spark.
			\item Refactorización de procesos ETL implementados con Sqoop y Airflow aplicando buenas prácticas para realizar la migración de datos desde Oracle a Impala.
			\item Creación de un dashboard analítico que provee un diagnóstico automático aplicando analytics y soluciones basadas en aprendizaje no supervisado con datos geográficos.
			\item Creación de un producto de datos automatizado que procesa un score créditicio de clientes usando datos de telecomunicaciones y bancarios, despliegue de servicios para el soporte de modelos de machine learning, bases de datos y un dashboard para la consulta de datos.
		\end{itemize}
	\end{cvsubsection}
	
	\begin{cvsubsection}{Consultor Independiente}{}{Enero 2020 - Actualidad}
		\begin{itemize}
			\item Armado de un programa de escritorio para computar métricas y elaborar reportes sobre sistemas de riego.
			\item Puesta en producción de un scraper web para el almacenamiento de datos y su posterior transformación utilizando AWS Batch, CloudWatch Events, Lambda, ECS, ECR implementando repositorios con pipelines de CI/CD.
			\item Armado de una solución que integra datos de redes sociales para el armado de dashboards analíticos.
			\item Creación de un dashboard analítico usando Apache Superset (montado sobre una EC2 y utilizando un pipeline de CI/CD) para consumir datos de diversas fuentes tales como RDS, Athena, Google Sheet.
		\end{itemize}
	\end{cvsubsection}
	
	\begin{cvsection}{Educación}
		\begin{cvsubsection}{Ingeniero en Sistemas de Información}{Universidad Tecnologica Nacional - Facultad Regional Tucumán}{2013 - 2018}
		\end{cvsubsection}
		\begin{cvsubsection}
			{cvsubsection}{Master in Management + Analytics}{Universidad Torcuato di Tella}{2018 - 2020}
		\end{cvsubsection}
	\end{cvsection}
	
	\begin{cvsection}{Certificaciones y logros}
		\begin{cvsubsection}{}{}{}
			\begin{itemize}
				\item \textbf{Septimo mejor promedio en UTN FRT} (2017) - Promedio 8.53
				\item \textbf{Apache Airflow Fundamentals} (Marzo 2021) - Astronomer Academy
			\end{itemize}
		\end{cvsubsection}
	\end{cvsection}
	
	\begin{cvsection}{Lenguajes y Tecnologías}
		\begin{cvsubsection}{}{}{}
			\begin{itemize}
				\item Python (librerías de ML, procesamiento de datos, data viz, dashboarding, desarrollo web, scripting, etc).
				\item Scala (Programación funcional, Spark, tests unitarios y de integración), R (librerías de ML, procesamiento de datos, Shiny y data viz).
				\item Bash, SQL y NoSQL.
				\item Apache Spark, Apache Airflow, Docker, Docker-Compose, K8s, Git workflow, conocimientos de desarrollo web, CI/CD.
				\item AWS, Azure.
			\end{itemize}
		\end{cvsubsection}
	\end{cvsection}
	
\end{document}
